{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Distributed Graph Processing using Apache Spark**"
      ],
      "metadata": {
        "id": "lSMMSQC0vdn4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Divyesh Ramani - 202201241**"
      ],
      "metadata": {
        "id": "Brt7aQ9pvp2u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Manan Patel - 202201310**"
      ],
      "metadata": {
        "id": "9Sn8tdefv3pF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "EQh_SyLJLYsH"
      },
      "outputs": [],
      "source": [
        "!pip install -q pyspark"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark import SparkContext, SparkConf\n",
        "conf = SparkConf().setAppName(\"appName\").setMaster(\"local\")\n",
        "sc = SparkContext(conf = conf)"
      ],
      "metadata": {
        "id": "A3NXRg5rLh7r"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "LWS1WmbiwBbA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "695cb1ec-f5c6-4f01-ce8a-92fdf3188215"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.types import *\n",
        "\n",
        "def read_nodes_from_file(file_path):\n",
        "    node = {}\n",
        "    with open(file_path, 'r', encoding='utf-8-sig') as f: # Specify 'utf-8-sig'\n",
        "        for line in f:\n",
        "            line = line.strip()\n",
        "            if line and line != \"Exit\":\n",
        "                if \"_\" in line:\n",
        "                    node_label, node_type = line.split(\"_\")\n",
        "                    node[node_label] = node_type\n",
        "                else:\n",
        "                    print(f\"Skipping invalid line: {line}\")\n",
        "    return node\n",
        "\n",
        "def read_edges_from_file(file_path, temp_graph):\n",
        "    with open(file_path, 'r', encoding='utf-8-sig') as f:  # Handle BOM\n",
        "        for line in f:\n",
        "            line = line.strip()\n",
        "            if line and line != \"Exit\":  # Skip empty lines and \"Exit\"\n",
        "                # Remove BOM if present:\n",
        "                if line.startswith('\\ufeff'):\n",
        "                    line = line[1:]\n",
        "                user_input = line.split(\"_\")\n",
        "                if (user_input[0] in temp_graph and user_input[1] in temp_graph):\n",
        "                    if ((user_input[2], 'o') in temp_graph[user_input[0]][1]):\n",
        "                        temp_graph[user_input[0]][1][(user_input[2], 'o')].append(int(user_input[1]))\n",
        "                    else:\n",
        "                        temp_graph[user_input[0]][1][(user_input[2], 'o')] = [int(user_input[1])]\n",
        "\n",
        "                    if ((user_input[2], 'i') in temp_graph[user_input[1]][1]):\n",
        "                        temp_graph[user_input[1]][1][(user_input[2], 'i')].append(int(user_input[0]))\n",
        "                    else:\n",
        "                        temp_graph[user_input[1]][1][(user_input[2], 'i')] = [int(user_input[0])]\n",
        "\n",
        "\n",
        "GraphNode_path = \"/content/drive/MyDrive/GraphNode.txt\"\n",
        "node = read_nodes_from_file(GraphNode_path)\n",
        "\n",
        "\n",
        "temp_graph = {}\n",
        "for key in node:\n",
        "  temp_graph[key]=[node[key], {}]\n",
        "GraphEdge_path = '/content/drive/MyDrive/GraphEdge.txt'  # Replace with your edge file path\n",
        "read_edges_from_file(GraphEdge_path, temp_graph)\n",
        "\n",
        "\n",
        "QueryNode_path = \"/content/drive/MyDrive/NewQueryNode.txt\"\n",
        "query_node = read_nodes_from_file(QueryNode_path)\n",
        "\n",
        "\n",
        "temp_query = {}\n",
        "for key in query_node:\n",
        "  temp_query[key]=[query_node[key], {}]\n",
        "QueryEdge_path = '/content/drive/MyDrive/NewQueryEdge.txt'\n",
        "read_edges_from_file(QueryEdge_path, temp_query)\n",
        "\n",
        "\n",
        "\n",
        "graph = []\n",
        "for key in temp_graph:\n",
        "  graph.append((int(key), temp_graph[key][0], temp_graph[key][1]))\n",
        "\n",
        "GraphRDD = sc.parallelize(graph)\n",
        "GraphRDD.persist()\n",
        "\n",
        "query = []\n",
        "for key in temp_query:\n",
        "  query.append((int(key), temp_query[key][0], temp_query[key][1]))\n",
        "\n",
        "QueryRDD = sc.parallelize(query)\n",
        "QueryRDD.persist()\n",
        "\n",
        "\n",
        "\n",
        "NumQuery=QueryRDD.count()\n",
        "segments = []\n",
        "data = QueryRDD.collect()\n",
        "for i in range(NumQuery):\n",
        "    node_label = data[i][1]\n",
        "    edge_list = list(data[i][2].keys())\n",
        "\n",
        "    tmp1 = [node_label]\n",
        "    tmp1.append(edge_list)\n",
        "\n",
        "    tmp2 = [node_label]\n",
        "    for j in range(len(edge_list)):\n",
        "        tmp2.append([edge_list[j]])\n",
        "\n",
        "    if i == 0 or i == QueryRDD.count() - 1:\n",
        "        segments.append(tmp1)\n",
        "    else:\n",
        "        segments.append(tmp2)\n",
        "\n",
        "#Initializing the ValidRDD which will initially be equal to the entire GraphRDD\n",
        "validRDD = GraphRDD\n",
        "validRDD = validRDD.map(lambda x: [x, []])\n",
        "#Iterating through the segments of the Query\n",
        "for i in range(NumQuery):\n",
        "  node_label = segments[i][0] #Node of the current Query segment.\n",
        "  edge_list = segments[i][1:] #Edges involved in the current Query segment.\n",
        "  #Shortlisting the nodes from ValidRDD which match our desired Node Label\n",
        "  shortlistedRDD = validRDD.filter(lambda x: x[0][1] == node_label)\n",
        "\n",
        "  #Getting a list of corresponding Edge Label and Edge Direction involved.\n",
        "  e_lab = []\n",
        "  e_dir = []\n",
        "  for j in range(len(edge_list)):\n",
        "      e_lab.append(edge_list[j][0][0])\n",
        "      e_dir.append(edge_list[j][0][1])\n",
        "\n",
        "  #Further shortlisting the nodes based on the edge list.\n",
        "  for j in range(len(e_lab)):\n",
        "      shortlistedRDD = shortlistedRDD.filter(lambda x: (e_lab[j], e_dir[j]) in x[0][2].keys())\n",
        "\n",
        "  #We broadcast the list of shortlisted nodes.\n",
        "  shortlisted_data = shortlistedRDD.collect()  # Collect data once\n",
        "  shortlisted_broadcast = sc.broadcast(shortlisted_data)  # Broadcast collected data\n",
        "\n",
        "  #Now we move to create a sample space for next possible node, neighbours of the current nodes.\n",
        "  newRDD = sc.parallelize([])\n",
        "  for j in range(len(shortlisted_data)):\n",
        "    current_label=shortlisted_data[j][0][0]\n",
        "    for k in range(len(e_lab)):\n",
        "      newRDD = newRDD.union(\n",
        "        GraphRDD.filter(lambda x: x[0] in shortlisted_broadcast.value[j][0][2].get((e_lab[k], e_dir[k]), []))\n",
        "        .map(lambda x: [x, shortlisted_broadcast.value[j][1] + [current_label]])  # Adjust j as needed\n",
        "      )\n",
        "\n",
        "  newRDD.persist()\n",
        "  validRDD=newRDD\n",
        "\n",
        "for element in validRDD.collect():\n",
        "  print(element[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iy38G8Dae-z-",
        "outputId": "2caeeadf-5e56-4624-9d81-56790f5dfbff"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[16, 2, 1, 3, 4, 14]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sc.stop()"
      ],
      "metadata": {
        "id": "RcDVnuycMdms"
      },
      "execution_count": 6,
      "outputs": []
    }
  ]
}